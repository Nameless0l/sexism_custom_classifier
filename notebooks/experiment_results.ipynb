{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-30-b64feccf5d0f>:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results_df2['feature_names']=results_df2['feature_names'].apply(lambda x: merge_list(x))\n",
      "<ipython-input-30-b64feccf5d0f>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results_df2['train_domain']=results_df2['train_domain'].apply(lambda x: merge_list(x))\n",
      "<ipython-input-30-b64feccf5d0f>:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results_df2['test_domain']=results_df2['test_domain'].apply(lambda x: merge_list(x))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_domain</th>\n",
       "      <th>test_domain</th>\n",
       "      <th>model_name</th>\n",
       "      <th>feature_names</th>\n",
       "      <th>macro avg f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>benevolent + hostile + other</td>\n",
       "      <td>benevolent + hostile + other</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>ngram</td>\n",
       "      <td>0.791033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>benevolent + hostile + other</td>\n",
       "      <td>benevolent + hostile + other</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>ngram + type_dependency</td>\n",
       "      <td>0.776007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>benevolent + hostile + other</td>\n",
       "      <td>benevolent + hostile + other</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>sentiment</td>\n",
       "      <td>0.498996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>benevolent + hostile + other</td>\n",
       "      <td>benevolent + hostile + other</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>sentiment + ngram</td>\n",
       "      <td>0.787287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>benevolent + hostile + other</td>\n",
       "      <td>benevolent + hostile + other</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>sentiment + ngram + type_dependency</td>\n",
       "      <td>0.779774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>benevolent + hostile + other</td>\n",
       "      <td>benevolent + hostile + other</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>sentiment + type_dependency</td>\n",
       "      <td>0.772004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>benevolent + hostile + other</td>\n",
       "      <td>benevolent + hostile + other</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>type_dependency</td>\n",
       "      <td>0.768605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>benevolent + hostile + other</td>\n",
       "      <td>benevolent + hostile + other</td>\n",
       "      <td>svm</td>\n",
       "      <td>ngram</td>\n",
       "      <td>0.794544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>benevolent + hostile + other</td>\n",
       "      <td>benevolent + hostile + other</td>\n",
       "      <td>svm</td>\n",
       "      <td>ngram + type_dependency</td>\n",
       "      <td>0.783147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>benevolent + hostile + other</td>\n",
       "      <td>benevolent + hostile + other</td>\n",
       "      <td>svm</td>\n",
       "      <td>sentiment</td>\n",
       "      <td>0.591229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>benevolent + hostile + other</td>\n",
       "      <td>benevolent + hostile + other</td>\n",
       "      <td>svm</td>\n",
       "      <td>sentiment + ngram</td>\n",
       "      <td>0.798103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>benevolent + hostile + other</td>\n",
       "      <td>benevolent + hostile + other</td>\n",
       "      <td>svm</td>\n",
       "      <td>sentiment + ngram + type_dependency</td>\n",
       "      <td>0.786645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>benevolent + hostile + other</td>\n",
       "      <td>benevolent + hostile + other</td>\n",
       "      <td>svm</td>\n",
       "      <td>sentiment + type_dependency</td>\n",
       "      <td>0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>benevolent + hostile + other</td>\n",
       "      <td>benevolent + hostile + other</td>\n",
       "      <td>svm</td>\n",
       "      <td>type_dependency</td>\n",
       "      <td>0.785999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     train_domain                    test_domain  \\\n",
       "0    benevolent + hostile + other   benevolent + hostile + other   \n",
       "1    benevolent + hostile + other   benevolent + hostile + other   \n",
       "2    benevolent + hostile + other   benevolent + hostile + other   \n",
       "3    benevolent + hostile + other   benevolent + hostile + other   \n",
       "4    benevolent + hostile + other   benevolent + hostile + other   \n",
       "5    benevolent + hostile + other   benevolent + hostile + other   \n",
       "6    benevolent + hostile + other   benevolent + hostile + other   \n",
       "7    benevolent + hostile + other   benevolent + hostile + other   \n",
       "8    benevolent + hostile + other   benevolent + hostile + other   \n",
       "9    benevolent + hostile + other   benevolent + hostile + other   \n",
       "10   benevolent + hostile + other   benevolent + hostile + other   \n",
       "11   benevolent + hostile + other   benevolent + hostile + other   \n",
       "12   benevolent + hostile + other   benevolent + hostile + other   \n",
       "13   benevolent + hostile + other   benevolent + hostile + other   \n",
       "\n",
       "             model_name                         feature_names  \\\n",
       "0   logistic_regression                                 ngram   \n",
       "1   logistic_regression               ngram + type_dependency   \n",
       "2   logistic_regression                             sentiment   \n",
       "3   logistic_regression                     sentiment + ngram   \n",
       "4   logistic_regression   sentiment + ngram + type_dependency   \n",
       "5   logistic_regression           sentiment + type_dependency   \n",
       "6   logistic_regression                       type_dependency   \n",
       "7                   svm                                 ngram   \n",
       "8                   svm               ngram + type_dependency   \n",
       "9                   svm                             sentiment   \n",
       "10                  svm                     sentiment + ngram   \n",
       "11                  svm   sentiment + ngram + type_dependency   \n",
       "12                  svm           sentiment + type_dependency   \n",
       "13                  svm                       type_dependency   \n",
       "\n",
       "    macro avg f1-score  \n",
       "0             0.791033  \n",
       "1             0.776007  \n",
       "2             0.498996  \n",
       "3             0.787287  \n",
       "4             0.779774  \n",
       "5             0.772004  \n",
       "6             0.768605  \n",
       "7             0.794544  \n",
       "8             0.783147  \n",
       "9             0.591229  \n",
       "10            0.798103  \n",
       "11            0.786645  \n",
       "12            0.761194  \n",
       "13            0.785999  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name='../results/results_rq1_20201120-182327.pkl'\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "results_df=[]\n",
    "with open(file_name, 'rb') as f:\n",
    "    results_df = pickle.load(f)\n",
    "    \n",
    "def merge_list(list_):\n",
    "    retVal=''\n",
    "    for i in list_:\n",
    "        retVal=' + '.join((retVal, i))\n",
    "    return retVal[2:]\n",
    "\n",
    "\n",
    "results_df2=results_df[['train_domain', 'train_domain_modified', 'test_domain', 'test_domain_modified', 'model_name', 'feature_names', 'macro avg f1-score',]]\n",
    "results_df2['feature_names']=results_df2['feature_names'].apply(lambda x: merge_list(x))\n",
    "results_df2['train_domain']=results_df2['train_domain'].apply(lambda x: merge_list(x))\n",
    "results_df2['test_domain']=results_df2['test_domain'].apply(lambda x: merge_list(x))\n",
    "\n",
    "results_df2.groupby(['train_domain', 'test_domain', 'model_name', 'feature_names'])['macro avg f1-score'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name='../results/results_rq1_20201120-182327.pkl'\n",
    "#file_name='../results/results_rq1_20201123-093450.pkl'\n",
    "#file_name='../results/results_rq1_20201123-122102.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_domain_modified</th>\n",
       "      <th>macro avg f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>False</td>\n",
       "      <td>0.739101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>svm</td>\n",
       "      <td>False</td>\n",
       "      <td>0.757266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model_name  train_domain_modified  macro avg f1-score\n",
       "0  logistic_regression                  False            0.739101\n",
       "1                  svm                  False            0.757266"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "results_df=[]\n",
    "with open(file_name, 'rb') as f:\n",
    "    results_df = pickle.load(f)\n",
    "    \n",
    "results_df2=results_df[['train_domain', 'train_domain_modified', 'test_domain', 'test_domain_modified', 'model_name', 'feature_names', 'macro avg f1-score',]]\n",
    "results_df2\n",
    "\n",
    "results_df2.groupby(['model_name', 'train_domain_modified'])['macro avg f1-score'].mean().reset_index()\n",
    "\n",
    "#df.groupby(['name', 'id', 'dept'])['total_sale'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_domain</th>\n",
       "      <th>test_domain</th>\n",
       "      <th>model_name</th>\n",
       "      <th>features</th>\n",
       "      <th>macro avg f1-score</th>\n",
       "      <th>sexist precision</th>\n",
       "      <th>sexist recall</th>\n",
       "      <th>nonsexist precision</th>\n",
       "      <th>nonsexist recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BHO</td>\n",
       "      <td>BHO</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>ngram  words (1, 3)  + bert_doc</td>\n",
       "      <td>0.799995</td>\n",
       "      <td>0.802408</td>\n",
       "      <td>0.795920</td>\n",
       "      <td>0.798053</td>\n",
       "      <td>0.804140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>BHO</td>\n",
       "      <td>BHO</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>sentiment + ngram  words (1, 4)  + ngram typed dependency (1, 1)   (with relation) + bert_doc</td>\n",
       "      <td>0.799606</td>\n",
       "      <td>0.798770</td>\n",
       "      <td>0.801686</td>\n",
       "      <td>0.801541</td>\n",
       "      <td>0.797679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BHO</td>\n",
       "      <td>BHO</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>ngram  words (1, 4)  + ngram typed dependency (1, 1)   (with relation) + bert_doc</td>\n",
       "      <td>0.799018</td>\n",
       "      <td>0.799589</td>\n",
       "      <td>0.798723</td>\n",
       "      <td>0.799582</td>\n",
       "      <td>0.799471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>BHO</td>\n",
       "      <td>BHO</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>ngram  words (1, 3)  + ngram typed dependency (1, 1)   (with relation) + bert_doc</td>\n",
       "      <td>0.798955</td>\n",
       "      <td>0.798676</td>\n",
       "      <td>0.800165</td>\n",
       "      <td>0.800244</td>\n",
       "      <td>0.797883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>BHO</td>\n",
       "      <td>BHO</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>sentiment + ngram  words (1, 3)  + ngram typed dependency (1, 1)   (with relation) + bert_doc</td>\n",
       "      <td>0.798784</td>\n",
       "      <td>0.799319</td>\n",
       "      <td>0.798409</td>\n",
       "      <td>0.799020</td>\n",
       "      <td>0.799266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>BHO</td>\n",
       "      <td>BHO</td>\n",
       "      <td>svm</td>\n",
       "      <td>sentiment + ngram  words (1, 1)  + bert_doc</td>\n",
       "      <td>0.762831</td>\n",
       "      <td>0.768882</td>\n",
       "      <td>0.757755</td>\n",
       "      <td>0.761728</td>\n",
       "      <td>0.768854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>BHO</td>\n",
       "      <td>BHO</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>sentiment + ngram  words (1, 4)</td>\n",
       "      <td>0.761894</td>\n",
       "      <td>0.733399</td>\n",
       "      <td>0.830602</td>\n",
       "      <td>0.804160</td>\n",
       "      <td>0.695857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>BHO</td>\n",
       "      <td>BHO</td>\n",
       "      <td>svm</td>\n",
       "      <td>sentiment + ngram  words (1, 4)</td>\n",
       "      <td>0.761868</td>\n",
       "      <td>0.739741</td>\n",
       "      <td>0.816135</td>\n",
       "      <td>0.795284</td>\n",
       "      <td>0.709805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>BHO</td>\n",
       "      <td>BHO</td>\n",
       "      <td>svm</td>\n",
       "      <td>sentiment</td>\n",
       "      <td>0.576232</td>\n",
       "      <td>0.569984</td>\n",
       "      <td>0.655406</td>\n",
       "      <td>0.592855</td>\n",
       "      <td>0.503434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>BHO</td>\n",
       "      <td>BHO</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>sentiment</td>\n",
       "      <td>0.507783</td>\n",
       "      <td>0.508487</td>\n",
       "      <td>0.575476</td>\n",
       "      <td>0.515145</td>\n",
       "      <td>0.446683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_domain test_domain           model_name  \\\n",
       "14           BHO         BHO  logistic_regression   \n",
       "52           BHO         BHO  logistic_regression   \n",
       "22           BHO         BHO  logistic_regression   \n",
       "16           BHO         BHO  logistic_regression   \n",
       "46           BHO         BHO  logistic_regression   \n",
       "..           ...         ...                  ...   \n",
       "91           BHO         BHO                  svm   \n",
       "49           BHO         BHO  logistic_regression   \n",
       "108          BHO         BHO                  svm   \n",
       "88           BHO         BHO                  svm   \n",
       "29           BHO         BHO  logistic_regression   \n",
       "\n",
       "                                                                                          features  \\\n",
       "14                                                                 ngram  words (1, 3)  + bert_doc   \n",
       "52   sentiment + ngram  words (1, 4)  + ngram typed dependency (1, 1)   (with relation) + bert_doc   \n",
       "22               ngram  words (1, 4)  + ngram typed dependency (1, 1)   (with relation) + bert_doc   \n",
       "16               ngram  words (1, 3)  + ngram typed dependency (1, 1)   (with relation) + bert_doc   \n",
       "46   sentiment + ngram  words (1, 3)  + ngram typed dependency (1, 1)   (with relation) + bert_doc   \n",
       "..                                                                                             ...   \n",
       "91                                                     sentiment + ngram  words (1, 1)  + bert_doc   \n",
       "49                                                                sentiment + ngram  words (1, 4)    \n",
       "108                                                               sentiment + ngram  words (1, 4)    \n",
       "88                                                                                       sentiment   \n",
       "29                                                                                       sentiment   \n",
       "\n",
       "     macro avg f1-score  sexist precision  sexist recall  nonsexist precision  \\\n",
       "14             0.799995          0.802408       0.795920             0.798053   \n",
       "52             0.799606          0.798770       0.801686             0.801541   \n",
       "22             0.799018          0.799589       0.798723             0.799582   \n",
       "16             0.798955          0.798676       0.800165             0.800244   \n",
       "46             0.798784          0.799319       0.798409             0.799020   \n",
       "..                  ...               ...            ...                  ...   \n",
       "91             0.762831          0.768882       0.757755             0.761728   \n",
       "49             0.761894          0.733399       0.830602             0.804160   \n",
       "108            0.761868          0.739741       0.816135             0.795284   \n",
       "88             0.576232          0.569984       0.655406             0.592855   \n",
       "29             0.507783          0.508487       0.575476             0.515145   \n",
       "\n",
       "     nonsexist recall  \n",
       "14           0.804140  \n",
       "52           0.797679  \n",
       "22           0.799471  \n",
       "16           0.797883  \n",
       "46           0.799266  \n",
       "..                ...  \n",
       "91           0.768854  \n",
       "49           0.695857  \n",
       "108          0.709805  \n",
       "88           0.503434  \n",
       "29           0.446683  \n",
       "\n",
       "[118 rows x 9 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 1200\n",
    "\n",
    "results_df_all=[]\n",
    "with open('../experiments/results_all.pkl', 'rb') as f:\n",
    "    results_df_all = pickle.load(f)\n",
    "    \n",
    "def get_feature_names(x, ngram_range, ngram_range_td, rel):\n",
    "    ll=[]\n",
    "    for i in x:\n",
    "        if i['name'] == 'ngram':\n",
    "            reduced='reduced' if i['feature_selection'] == True else ''\n",
    "            ll.append(' '.join((i['name'], ' words', str(ngram_range[0]), reduced)))\n",
    "        elif i['name'] == 'type_dependency':\n",
    "            reduced='reduced' if i['feature_selection'] == True else ''\n",
    "            ll.append(' '.join(('ngram typed dependency', str(ngram_range_td[0]), reduced, rel)))\n",
    "        else:\n",
    "            ll.append(i['name'])\n",
    "    return ' + '.join(ll)\n",
    "\n",
    "def format_feature_names(r):\n",
    "    ngram_range=''\n",
    "    ngram_range_td=''\n",
    "    rel=''\n",
    "    \n",
    "    if 'features__ngram__feature_extraction__ngram_range' in r['param_grid'].keys():\n",
    "        ngram_range=r['param_grid']['features__ngram__feature_extraction__ngram_range']\n",
    "    if 'features__type_dependency__feature_extraction__ngram_range' in r['param_grid'].keys():\n",
    "        ngram_range_td=r['param_grid']['features__type_dependency__feature_extraction__ngram_range']\n",
    "    if 'features__type_dependency__feature_extraction__type_dep_file_name' in r['param_grid'].keys():\n",
    "        v=r['param_grid']['features__type_dependency__feature_extraction__type_dep_file_name'][0]\n",
    "        rel=' (with relation)' if 'not_add_relation' in v else ' (without relation)'\n",
    "    return get_feature_names(r['features'], ngram_range, ngram_range_td, rel)\n",
    "\n",
    "def format_domain_name(r):\n",
    "    dataset=r['dataset']\n",
    "    modified='M' if r['modified'] == True else ''\n",
    "    tr=''\n",
    "    for d in dataset:\n",
    "        tr=''.join((tr,d[0].upper()))\n",
    "    return ''.join((tr,modified))\n",
    "\n",
    "results_df_all.sort_values(by=['macro avg f1-score'], ascending=False)\n",
    "\n",
    "df_group=results_df_all[(results_df_all['model_name'] != 'gender_word') &\n",
    "                       (results_df_all['model_name'] != 'threshold_classifier')].groupby(\n",
    "    ['train_domain','test_domain','model_name','features'])[\n",
    "    ['macro avg f1-score', 'sexist precision','sexist recall', \n",
    "     'nonsexist precision','nonsexist recall']].mean().reset_index()\n",
    "df_group.sort_values(by=['macro avg f1-score'], ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:thesis2_py3]",
   "language": "python",
   "name": "conda-env-thesis2_py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
