{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_domain</th>\n",
       "      <th>test_domain</th>\n",
       "      <th>model_name</th>\n",
       "      <th>features</th>\n",
       "      <th>macro avg f1-score</th>\n",
       "      <th>sexist precision</th>\n",
       "      <th>sexist recall</th>\n",
       "      <th>nonsexist precision</th>\n",
       "      <th>nonsexist recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BHO</td>\n",
       "      <td>BHO</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>ngram  words (1, 3)  + bert_doc</td>\n",
       "      <td>0.799995</td>\n",
       "      <td>0.802408</td>\n",
       "      <td>0.795920</td>\n",
       "      <td>0.798053</td>\n",
       "      <td>0.804140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>BHO</td>\n",
       "      <td>BHO</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>sentiment + ngram  words (1, 4)  + ngram typed dependency (1, 1)   (with relation) + bert_doc</td>\n",
       "      <td>0.799606</td>\n",
       "      <td>0.798770</td>\n",
       "      <td>0.801686</td>\n",
       "      <td>0.801541</td>\n",
       "      <td>0.797679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BHO</td>\n",
       "      <td>BHO</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>ngram  words (1, 4)  + ngram typed dependency (1, 1)   (with relation) + bert_doc</td>\n",
       "      <td>0.799018</td>\n",
       "      <td>0.799589</td>\n",
       "      <td>0.798723</td>\n",
       "      <td>0.799582</td>\n",
       "      <td>0.799471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>BHO</td>\n",
       "      <td>BHO</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>ngram  words (1, 3)  + ngram typed dependency (1, 1)   (with relation) + bert_doc</td>\n",
       "      <td>0.798955</td>\n",
       "      <td>0.798676</td>\n",
       "      <td>0.800165</td>\n",
       "      <td>0.800244</td>\n",
       "      <td>0.797883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>BHO</td>\n",
       "      <td>BHO</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>sentiment + ngram  words (1, 3)  + ngram typed dependency (1, 1)   (with relation) + bert_doc</td>\n",
       "      <td>0.798784</td>\n",
       "      <td>0.799319</td>\n",
       "      <td>0.798409</td>\n",
       "      <td>0.799020</td>\n",
       "      <td>0.799266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>BHO</td>\n",
       "      <td>BHO</td>\n",
       "      <td>svm</td>\n",
       "      <td>sentiment + ngram  words (1, 1)  + bert_doc</td>\n",
       "      <td>0.762831</td>\n",
       "      <td>0.768882</td>\n",
       "      <td>0.757755</td>\n",
       "      <td>0.761728</td>\n",
       "      <td>0.768854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>BHO</td>\n",
       "      <td>BHO</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>sentiment + ngram  words (1, 4)</td>\n",
       "      <td>0.761894</td>\n",
       "      <td>0.733399</td>\n",
       "      <td>0.830602</td>\n",
       "      <td>0.804160</td>\n",
       "      <td>0.695857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>BHO</td>\n",
       "      <td>BHO</td>\n",
       "      <td>svm</td>\n",
       "      <td>sentiment + ngram  words (1, 4)</td>\n",
       "      <td>0.761868</td>\n",
       "      <td>0.739741</td>\n",
       "      <td>0.816135</td>\n",
       "      <td>0.795284</td>\n",
       "      <td>0.709805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>BHO</td>\n",
       "      <td>BHO</td>\n",
       "      <td>svm</td>\n",
       "      <td>sentiment</td>\n",
       "      <td>0.576232</td>\n",
       "      <td>0.569984</td>\n",
       "      <td>0.655406</td>\n",
       "      <td>0.592855</td>\n",
       "      <td>0.503434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>BHO</td>\n",
       "      <td>BHO</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>sentiment</td>\n",
       "      <td>0.507783</td>\n",
       "      <td>0.508487</td>\n",
       "      <td>0.575476</td>\n",
       "      <td>0.515145</td>\n",
       "      <td>0.446683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_domain test_domain           model_name  \\\n",
       "14           BHO         BHO  logistic_regression   \n",
       "52           BHO         BHO  logistic_regression   \n",
       "22           BHO         BHO  logistic_regression   \n",
       "16           BHO         BHO  logistic_regression   \n",
       "46           BHO         BHO  logistic_regression   \n",
       "..           ...         ...                  ...   \n",
       "91           BHO         BHO                  svm   \n",
       "49           BHO         BHO  logistic_regression   \n",
       "108          BHO         BHO                  svm   \n",
       "88           BHO         BHO                  svm   \n",
       "29           BHO         BHO  logistic_regression   \n",
       "\n",
       "                                                                                          features  \\\n",
       "14                                                                 ngram  words (1, 3)  + bert_doc   \n",
       "52   sentiment + ngram  words (1, 4)  + ngram typed dependency (1, 1)   (with relation) + bert_doc   \n",
       "22               ngram  words (1, 4)  + ngram typed dependency (1, 1)   (with relation) + bert_doc   \n",
       "16               ngram  words (1, 3)  + ngram typed dependency (1, 1)   (with relation) + bert_doc   \n",
       "46   sentiment + ngram  words (1, 3)  + ngram typed dependency (1, 1)   (with relation) + bert_doc   \n",
       "..                                                                                             ...   \n",
       "91                                                     sentiment + ngram  words (1, 1)  + bert_doc   \n",
       "49                                                                sentiment + ngram  words (1, 4)    \n",
       "108                                                               sentiment + ngram  words (1, 4)    \n",
       "88                                                                                       sentiment   \n",
       "29                                                                                       sentiment   \n",
       "\n",
       "     macro avg f1-score  sexist precision  sexist recall  nonsexist precision  \\\n",
       "14             0.799995          0.802408       0.795920             0.798053   \n",
       "52             0.799606          0.798770       0.801686             0.801541   \n",
       "22             0.799018          0.799589       0.798723             0.799582   \n",
       "16             0.798955          0.798676       0.800165             0.800244   \n",
       "46             0.798784          0.799319       0.798409             0.799020   \n",
       "..                  ...               ...            ...                  ...   \n",
       "91             0.762831          0.768882       0.757755             0.761728   \n",
       "49             0.761894          0.733399       0.830602             0.804160   \n",
       "108            0.761868          0.739741       0.816135             0.795284   \n",
       "88             0.576232          0.569984       0.655406             0.592855   \n",
       "29             0.507783          0.508487       0.575476             0.515145   \n",
       "\n",
       "     nonsexist recall  \n",
       "14           0.804140  \n",
       "52           0.797679  \n",
       "22           0.799471  \n",
       "16           0.797883  \n",
       "46           0.799266  \n",
       "..                ...  \n",
       "91           0.768854  \n",
       "49           0.695857  \n",
       "108          0.709805  \n",
       "88           0.503434  \n",
       "29           0.446683  \n",
       "\n",
       "[118 rows x 9 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 1200\n",
    "\n",
    "results_df_all=[]\n",
    "with open('../experiments/results_all.pkl', 'rb') as f:\n",
    "    results_df_all = pickle.load(f)\n",
    "    \n",
    "def get_feature_names(x, ngram_range, ngram_range_td, rel):\n",
    "    ll=[]\n",
    "    for i in x:\n",
    "        if i['name'] == 'ngram':\n",
    "            reduced='reduced' if i['feature_selection'] == True else ''\n",
    "            ll.append(' '.join((i['name'], ' words', str(ngram_range[0]), reduced)))\n",
    "        elif i['name'] == 'type_dependency':\n",
    "            reduced='reduced' if i['feature_selection'] == True else ''\n",
    "            ll.append(' '.join(('ngram typed dependency', str(ngram_range_td[0]), reduced, rel)))\n",
    "        else:\n",
    "            ll.append(i['name'])\n",
    "    return ' + '.join(ll)\n",
    "\n",
    "def format_feature_names(r):\n",
    "    ngram_range=''\n",
    "    ngram_range_td=''\n",
    "    rel=''\n",
    "    \n",
    "    if 'features__ngram__feature_extraction__ngram_range' in r['param_grid'].keys():\n",
    "        ngram_range=r['param_grid']['features__ngram__feature_extraction__ngram_range']\n",
    "    if 'features__type_dependency__feature_extraction__ngram_range' in r['param_grid'].keys():\n",
    "        ngram_range_td=r['param_grid']['features__type_dependency__feature_extraction__ngram_range']\n",
    "    if 'features__type_dependency__feature_extraction__type_dep_file_name' in r['param_grid'].keys():\n",
    "        v=r['param_grid']['features__type_dependency__feature_extraction__type_dep_file_name'][0]\n",
    "        rel=' (with relation)' if 'not_add_relation' in v else ' (without relation)'\n",
    "    return get_feature_names(r['features'], ngram_range, ngram_range_td, rel)\n",
    "\n",
    "def format_domain_name(r):\n",
    "    dataset=r['dataset']\n",
    "    modified='M' if r['modified'] == True else ''\n",
    "    tr=''\n",
    "    for d in dataset:\n",
    "        tr=''.join((tr,d[0].upper()))\n",
    "    return ''.join((tr,modified))\n",
    "\n",
    "results_df_all.sort_values(by=['macro avg f1-score'], ascending=False)\n",
    "\n",
    "df_group=results_df_all[(results_df_all['model_name'] != 'gender_word') &\n",
    "                       (results_df_all['model_name'] != 'threshold_classifier')].groupby(\n",
    "    ['train_domain','test_domain','model_name','features'])[\n",
    "    ['macro avg f1-score', 'sexist precision','sexist recall', \n",
    "     'nonsexist precision','nonsexist recall']].mean().reset_index()\n",
    "df_group.sort_values(by=['macro avg f1-score'], ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:thesis2_py3]",
   "language": "python",
   "name": "conda-env-thesis2_py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
